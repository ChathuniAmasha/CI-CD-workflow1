{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Ucb9sU-8lc",
        "outputId": "da91cf8c-5ccd-4f2b-8743-ee41bfa18659"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, treebank\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tag import DefaultTagger, RegexpTagger, UnigramTagger, BigramTagger, TrigramTagger\n",
        "from nltk.chunk import tree2conlltags\n",
        "from nltk.classify import MaxentClassifier\n",
        "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Download required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "nltk.download('treebank')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample web scraping\n",
        "url = \"https://www.bbc.com/news/business-64303166\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "raw_text = soup.get_text()\n",
        "\n",
        "# Clean and preprocess text\n",
        "text = re.sub(r'[^a-zA-Z0-9\\s]', '', raw_text)\n",
        "tokens = word_tokenize(text.lower())\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens = [word for word in tokens if word not in stop_words]\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "# Statistics\n",
        "unique_tokens = len(set(tokens))\n",
        "total_lemmas = len(lemmatized_tokens)\n",
        "unique_lemmas = len(set(lemmatized_tokens))\n",
        "\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "tokenizer = PunktSentenceTokenizer()\n",
        "sentences = tokenizer.tokenize(raw_text)\n",
        "num_sentences = len(sentences)\n",
        "avg_words = total_tokens / num_sentences if num_sentences else 0\n",
        "\n",
        "print(\"Total tokens:\", total_tokens)\n",
        "print(\"Unique tokens:\", unique_tokens)\n",
        "print(\"Lemmatized tokens:\", total_lemmas)\n",
        "print(\"Unique lemmatized tokens:\", unique_lemmas)\n",
        "print(\"Number of sentences:\", num_sentences)\n",
        "print(\"Average words per sentence:\", avg_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF4jN4DUGFch",
        "outputId": "d861b699-dca6-472b-ffde-c77ba2d2c43c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 304\n",
            "Unique tokens: 262\n",
            "Lemmatized tokens: 304\n",
            "Unique lemmatized tokens: 261\n",
            "Number of sentences: 10\n",
            "Average words per sentence: 30.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences = treebank.tagged_sents()\n",
        "split = int(0.8 * len(tagged_sentences))\n",
        "train_data = tagged_sentences[:split]\n",
        "test_data = tagged_sentences[split:]\n"
      ],
      "metadata": {
        "id": "ZkBZc4qtGfsf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "default_tagger = DefaultTagger('NN')\n",
        "accuracy_default = default_tagger.evaluate(test_data)\n",
        "print(\"Default Tagger Accuracy:\", accuracy_default)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEbNvHeNGiHc",
        "outputId": "84f87869-1d4f-424c-ea1c-805e600d510f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-1232569748.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  accuracy_default = default_tagger.evaluate(test_data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Tagger Accuracy: 0.1447677029791906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patterns = [\n",
        "    (r'.*ing$', 'VBG'),  # gerunds\n",
        "    (r'.*ed$', 'VBD'),   # past tense verbs\n",
        "    (r'.*es$', 'VBZ'),   # 3rd person singular present\n",
        "    (r'.*ould$', 'MD'),  # modals\n",
        "    (r'.*\\'s$', 'POS'),  # possessives\n",
        "    (r'^-?[0-9]+$', 'CD'),  # cardinal numbers\n",
        "    (r'.*', 'NN')        # default noun\n",
        "]\n",
        "regex_tagger = RegexpTagger(patterns)\n",
        "print(\"Regex Tagger Accuracy:\", regex_tagger.evaluate(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk5n9m8FGl-S",
        "outputId": "17bf7f7f-ab68-4651-a5e3-3f4a039fa7d4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-9-1417140765.py:11: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Regex Tagger Accuracy:\", regex_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regex Tagger Accuracy: 0.20190628274864014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tagger = UnigramTagger(train_data)\n",
        "print(\"Unigram Accuracy:\", unigram_tagger.evaluate(test_data))\n",
        "\n",
        "bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print(\"Bigram Accuracy:\", bigram_tagger.evaluate(test_data))\n",
        "\n",
        "trigram_tagger = TrigramTagger(train_data, backoff=bigram_tagger)\n",
        "print(\"Trigram Accuracy:\", trigram_tagger.evaluate(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTLF9xoSGp-W",
        "outputId": "d1005e26-1eef-4c10-fe96-ed06da90e3cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-697837306.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Unigram Accuracy:\", unigram_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Accuracy: 0.8608213982733669\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-697837306.py:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Bigram Accuracy:\", bigram_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Accuracy: 0.8679075802185737\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-10-697837306.py:8: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Trigram Accuracy:\", trigram_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Accuracy: 0.8678077748390638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "combined_tagger = TrigramTagger(train_data,\n",
        "                     backoff=BigramTagger(train_data,\n",
        "                     backoff=UnigramTagger(train_data,\n",
        "                     backoff=DefaultTagger('NN'))))\n",
        "print(\"Combined Tagger Accuracy:\", combined_tagger.evaluate(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktxOoQUxGycC",
        "outputId": "802a9b7e-71b3-43ac-d6f0-f1f94e84bd89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-11-2148400132.py:5: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Combined Tagger Accuracy:\", combined_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Tagger Accuracy: 0.8844253705274714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_tagger = ClassifierBasedPOSTagger(train=train_data, classifier_builder=MaxentClassifier.train)\n",
        "print(\"Classifier-Based Tagger Accuracy:\", classifier_tagger.evaluate(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6ryII_GG210",
        "outputId": "26c41e40-1eb8-431e-8e16-b813cfd27a13"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ==> Training (100 iterations)\n",
            "\n",
            "      Iteration    Log Likelihood    Accuracy\n",
            "      ---------------------------------------\n",
            "             1          -3.82864        0.008\n",
            "             2          -0.76705        0.957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/classify/maxent.py:1380: RuntimeWarning: overflow encountered in power\n",
            "  exp_nf_delta = 2**nf_delta\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/classify/maxent.py:1382: RuntimeWarning: invalid value encountered in multiply\n",
            "  sum1 = numpy.sum(exp_nf_delta * A, axis=0)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/classify/maxent.py:1383: RuntimeWarning: invalid value encountered in multiply\n",
            "  sum2 = numpy.sum(nf_exp_nf_delta * A, axis=0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Final               nan        0.984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-3518006484.py:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  print(\"Classifier-Based Tagger Accuracy:\", classifier_tagger.evaluate(test_data))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier-Based Tagger Accuracy: 0.9277908079245472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a small sample or text from earlier steps\n",
        "sample = \"Apple Inc. was founded by Steve Jobs and Steve Wozniak in California.\"\n",
        "\n",
        "# Check if the resource is available before using it\n",
        "try:\n",
        "    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n",
        "    print(\"averaged_perceptron_tagger_eng found.\")\n",
        "except LookupError:\n",
        "    print(\"averaged_perceptron_tagger_eng not found. Please run the first cell to download resources.\")\n",
        "\n",
        "# POS tagging\n",
        "pos_tags = pos_tag(word_tokenize(sample))\n",
        "\n",
        "# Named Entity Recognition\n",
        "tree = ne_chunk(pos_tags)\n",
        "\n",
        "# Print named entities\n",
        "print(\"Named Entities:\")\n",
        "print(tree)\n",
        "\n",
        "# Extracting named entities in IOB format\n",
        "iob = tree2conlltags(tree)\n",
        "print(\"\\nNamed Entities (IOB format):\")\n",
        "for word, pos, ner in iob:\n",
        "    if ner != 'O':\n",
        "        print(f\"{word}: {ner}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "819a6XQdJRMb",
        "outputId": "9375efad-1360-433f-d37b-ecc20f71a009"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "averaged_perceptron_tagger_eng found.\n",
            "Named Entities:\n",
            "(S\n",
            "  (PERSON Apple/NNP)\n",
            "  (ORGANIZATION Inc./NNP)\n",
            "  was/VBD\n",
            "  founded/VBN\n",
            "  by/IN\n",
            "  (PERSON Steve/NNP Jobs/NNP)\n",
            "  and/CC\n",
            "  (PERSON Steve/NNP Wozniak/NNP)\n",
            "  in/IN\n",
            "  (GPE California/NNP)\n",
            "  ./.)\n",
            "\n",
            "Named Entities (IOB format):\n",
            "Apple: B-PERSON\n",
            "Inc.: B-ORGANIZATION\n",
            "Steve: B-PERSON\n",
            "Jobs: I-PERSON\n",
            "Steve: B-PERSON\n",
            "Wozniak: I-PERSON\n",
            "California: B-GPE\n"
          ]
        }
      ]
    }
  ]
}
